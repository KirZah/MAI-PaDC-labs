# Параллельные и распределённые вычисления (ПиРВ)
---
Тут я делаю свои лабы...


---
## Lab 1 - Приступаем к работе...
---
### __Задача__ 
Вывести на экран числа от 1 до 65535.

### __Решение__ 

Мы создаем функцию ***print_gpu()*** на устройстве (GPU), которая будет вызываться из CPU. 
```
__global__ void print_gpu(char separator) {
	printf("%d%c", blockIdx.x + 1, separator); 
}
```
Эта функция будет вызываться следующей строкой кода (в нашем случае n = 65535):
```
print_gpu<<<n, 1>>>(separator); // n блоков, 1 нить
```

### __Выводы__ (но будем серьёзны... какие тут могут быть выводы...)
Да, GPU ДЕЙСТВИТЕЛЬНО быстрее. Особенно, когда мы передаем символ новой строки '\ n' в качестве параметра в print_gpu.


---
## Lab 2 - Использование различных типов памяти
---

### __Задача__ 
Нужно найти решение любого уравнения. 

Для простоты я выбрал следующее линейное уравнение:

__a?x + b = 0__.

### __Решение__ 

Приводим уравнение к следующему виду: f(x) = 0.
Определяем границы, на которых находится решение. И делим эту область на равные промежутки. Вычисляем значение f(x) на каждом отрезке, и ищем 2 рядом стоящих отрезка, на которых значения f(x) имеют разный знак.
Если таких промежутков не нашлось, то виной тому могут быть следующие причины:

- *В заданных границах решений нет*
- *__(Не в нашем случае)__ Отрезок разбит на слишком широкие промежутки.* Из-за этого мы можем пропустить место, где функция проходит через ноль. Так как она успевает вернуться обратно. Таким образом мы можем потерять даже не одно, а сразу два решения.


#### Варианты реализации

##### Реализация 1 (используя ```__global__``` память)
**Плюсы (+):** Цикл находится на CPU, чтобы не занимать кучу тредов GPU без весомой на то причины. Так как иначе бы он выполнял одно и то же действие с одними и теми же параметрами во всех выделенных ему потоках.

**Минусы (-):** К сожалению, в данном случае можно использовать только медленную глобальную (global) память.

```
__global__  find_borders() {
	...
}

__host__ find_solution(...) {
	while (radius > epsilon) {
		...
	}
}

__host__ int main() {
    ...
    find_solution(...);
    ...
}
```

##### Реализация 2 (используя ```__shared__``` память)
**Плюсы (+):** Можно использовать более быструю (shared) память которая находится внутри блока.

**Минусы (-):** Цикл находится на GPU из-за чего в нём занимается очень много тредов просто так для одного и того же действия с одними и теми же параметрами.
```
__device__  find_borders() {
	...
}

__global__ find_solution(...) {
	while (radius > epsilon) {
		...
	}
}

__host__ int main() {
    ...
    find_solution<<<...>>>(...);
    ...
}
```

### __Выводы__

При сравнении реализации задачи на CPU и GPU, выигрыш в производительности довольно сильно склонился в сторону CPU. Разрыв между GPU и CPU существенен при любых N. Это так ввиду ***особенности алгоритма: в нём используется цикл***. Так как тактовая частота процессора выше чем тактовая частота видеокарты, то и цикл в нём выполняется быстрее. Плюсы видеокарты же заключаются в выполнении *одинаковых операций с __разными__ параметрами*. В нашем же случае (в реализации через shared память) ей в цикле приходится выполнять *одинаковые операции с __одинаковыми__ параметрами*. Более явно вывод о том, что выбранный алгоритм не оптимален для видеокарты, можно подтвердить тем, что реализация через более медленную глобальную память показала себя лучше, так как выполнение цикла в ней происходит на CPU. Анализ производительности осуществлялся на основе показателей времени, рассчитываемых непосредственно в коде программы.

Разница между временем исполнения GPU (с глобальной памятью и циклом на CPU) и CPU с глобальной памятью и CPU довольно медленно уменьшалась. Из этого можно сделать вывод о том, что для решения задач, для которых необходим цикл с одинаковыми параметрами, __лучше использовать CPU__. 

---
## Lab 3
---

### __Задача__ 

### __Решение__ 

### __Выводы__
